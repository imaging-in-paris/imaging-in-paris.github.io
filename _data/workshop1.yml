- speaker: Nicolas Bonneel
  title: "Sliced Partial Optimal Transport"
  abstract: "Sliced optimal transport is a blazing fast way to compute a notion of optimal transport between uniform measures supported on point clouds via 1-d projections. However, it requires these point clouds to have the same cardinality. This talk will show a fast numerical scheme to compute partial optimal transport in 1-d : this corresponds to solving an alignment problem often solved with dynamic programming, though our solution is much faster. We integrate this 1-d alignment algorithm within a sliced transport framework, for applications such as color transfer. We also make use of sliced partial optimal transport to solve point cloud registration tasks such as those traditionally solved with ICP. I'll show results involving hundreds of thousands of points computed within seconds or minutes. I'll also show preliminary results on sliced partial Wasserstein barycenters."

- speaker: Xavier Bresson
  title: "Convolutional Neural Networks on Graphs"
  abstract: "In the past years, deep learning methods have achieved unprecedented performance on a broad range of problems in various fields from computer vision to speech recognition. So far research has mainly focused on developing deep learning methods for grid-structured data, while many important applications have to deal with graph-structured data. Such geometric data are becoming increasingly important in computer graphics and 3D vision, sensor networks, drug design, biomedicine, recommendation systems, and web applications. The purpose of this talk is to introduce the emerging field of deep learning on graphs, overview existing solutions as well as applications for this class of problems."

- speaker: Blanche Buet
  title: "A varifold approach to surface approximation and curvature estimation on point clouds"
  abstract: "We propose a natural framework for the study of surfaces and their different discretizations based on varifolds. Varifolds have been introduced by Almgren to carry out the study of minimal surfaces. Though mainly used in the context of rectifiable sets, they turn out to be well suited to the study of discrete type objects as well. Let us briefly explain what a \\( d \\)-varifold is: it is a Radon measure on \\( \\Omega \\times G_{d,n} \\) where \\( G_{d,n} = \\{ d\\text{-vector plane of } \\mathbb{R}^n \\} \\) is the \\( d \\)--Grassmanian. It can be equivalently understood as the data of a Radon measure \\( \\mu \\) on \\( \\mathbb{R}^n \\) and a probability measure \\( \\nu_x \\) on \\( G_{d,n} \\) at each point \\( x \\) in the support of \\( \\mu \\). Using this point of view, we can easily associate a \\( d \\)-varifold with a \\( d \\)-submanifold \\( M \\) of \\( \\mathbb{R}^n \\): we take the surface measure for \\( \\mu \\) (the \\( d \\)-Hausdorff measure restricted to \\( M \\), which can be weighted) and for \\( \\nu_x \\), we take the Dirac mass at the tangent plane \\( T_x M \\) on \\( G_{d,n} \\). Loosely speaking, mass and tangent planes are enough to define a varifold. Hence, given a finite set of points  \\( \\{ x_i \\}_{i=1 \\ldots N} \\subset \\mathbb{R}^n \\),
weighted by masses \\( \\{ m_i \\}_{i=1 \\ldots N} \\subset \\mathbb{R}_+ \\),
and provided with directions \\( \\{ P_i \\}_{i=1 \\ldots N} \\subset G_{d,n} \\),
we associate the \\( d \\)-varifold
\\[
V_N = \\sum_{i=1}^N m_i , \\delta_{(x_i, P_i)} .
\\]
While the structure of varifold is flexible enough to adapt to both regular and discrete objects, it allows to define variational notions of mean curvature and second fundamental form based on the divergence theorem. Thanks to a regularization of these weak formulations, we propose a notion of discrete curvature (actually a family of discrete curvatures associated with a regularization scale) relying only on the varifold structure. We prove nice convergence properties involving a natural growth assumption: the scale of regularization must be large with respect to the accuracy of the discretization. We performed numerical computations of mean curvature and Gaussian curvature on point clouds in \\( \\mathbb{R}^3 \\) to illustrate this approach.
Joint work with Gian Paolo Leonardi (Modena) and Simon Masnou (Lyon)."

- speaker: Caroline Chaux
  title: "From the modelization of direct problems in image processing to the resolution of inverse problems"
  abstract: "In this work, we are interested in the resolution of inverse problems raised in many image processing applications. We considered inverse problems starting from models (understanding the acquisition process), then addressing their resolution (formulated as an optimization problem) while considering the parameters or hyperparameters involved all along the process (e.g. noise nature/intensity, regularization parameters). Different models will be considered corresponding to different application cases such as tensor factorization, source separation or time-frequency inpainting. All these issues have been addressed by adopting a variational approach leading to various optimization problems that we propose to solve by developing proximal approaches."

- speaker: Emilie Chouzenoux
  title: "Deep Unfolding of a Proximal Interior Point Method for Image Restoration"
  abstract: "Variational methods have started to be widely applied to ill-posed inverse problems since they have the ability to embed 
  prior knowledge about the solution. However, the level of performance of these methods significantly depends on a set of parameters, 
  which can be estimated through computationally expensive and time-consuming processes. In contrast, deep learning offers very generic and efficient architectures, at the expense of explainability, since it is often used as a black-box, without any fine control over its output. Deep unfolding provides a convenient approach to combine variational-based and deep learning approaches. Starting from a variational formulation for image restoration, we develop iRestNet, a neural network architecture obtained by unfolding an interior point proximal algorithm. Hard constraints, encoding desirable properties for the restored image, are incorporated into the network thanks to a logarithmic barrier, while the barrier parameter, the stepsize, and the penalization weight are learned by the network. We derive explicit expressions for the gradient of the proximity operator for various choices of constraints, which allows training iRestNet with gradient descent and backpropagation. In addition, we provide theoretical results regarding the stability of the network. Numerical experiments on image deblurring problems show that the proposed approach outperforms both state-of-the-art variational and machine learning methods in terms of image quality.
joint work with C. Bertocchi, M.C. Corbineau, J.C. Pesquet and M. Prato."

- speaker: Camille Couprie
  title: "Image generative modeling for future prediction or inspirational purposes"
  abstract: "Generative models, and in particular adversarial ones, are becoming prevalent in computer vision as they enable enhancing artistic creation, inspire designers, prove usefulness in semi-supervised learning or robotics applications. An important prerequisite towards intelligent behavior is the ability to anticipate future events. Predicting the appearance of future video frames is a proxy task towards pursuing this ability. We will present how generative adversarial networks (GANs) can help, and novel approaches predicting in higher level feature spaces of semantic segmentations. In a second part, we will see how to develop the abilities of GANs to deviate from training examples to generate novel images. Finally, as a limitation of GANs is the production of raw images of low resolution, we present solutions to produce vectorized results."

- speaker: Vincent Duval
  title: "An atomic norm perspective on total variation regularization in image processing"
  abstract: "It is folklore knowledge that the total (gradient) variation regularization tends to promote piecewise constant ``cartoon-like'' images. In this talk I will relate that property to the description of the extreme points of the total variation unit ball. 
These extreme points have been characterized by Ambrosio, Caselles, Masnou and Morel as the indicator functions of ``simple sets''. I will explain how it is possible to describe the solutions of variational problems as a sum of such functions, by using a general representation principle.
This is a joint work with C. Boyer, A. Chambolle, Y. De Castro, F. de Gournay and P. Weiss."

- speaker: Albert Fannjiang
  title: "Blind Ptychography: Theory and Algorithm"
  abstract: "Blind ptychography is a phase retrieval method using multiple coded diffraction patterns from different, overlapping parts of the unknown extended object illuminated with an unknown window function. As such blind ptychography is the inverse problem of simultaneous recovery of the object and the window function given the intensities of  the windowed Fourier transform. 
We derive a general set of conditions under which the object and the window function can be uniquely determined up to a scaling factor and an affine phase factor. We also characterize all the other ambiguities inherent to the raster scan which consists of the shift positions of  the standard windowed Fourier transform and propose an explicit remedy. Finally, we present  a reconstruction algorithm based on the Douglas-Rachford Splitting with initialization informed by the uniqueness theory."

- speaker: Dirk Lorenz
  title: "Quadratically regularized optimal transport"
  abstract: "Among regularization techniques for optimal transport, entropic regularization has played a pivotal rule. The main reason may be its computational simplicity: the Sinkhorn-Knopp iteration can be implemented in two- or even one line ad enjoys a linear convergence rate. However, some care is needed to calculate optimizer for small regularization parameters and convergence can be quite slow for badly behaved data. Faster algorithms, e.g. Newton methods, are hard to analyze and tend to be unstable in practice. Moreover, the continuous theory is intricate in this case and takes place in Orlicz-Luxemburg spaces (as we will illustrate in this talk).
After sketching parts of the continuous theory for entropic regularization, we will analyze a different regularizer, namely a simple quadratic penalty. First our focus lies on the continuous case where it is still quite challenging to show existence of suitable solutions for the dual problem. Then we will derive different numerical methods for the discrete problem which include a globally convergent Newton method which converges very fast to high accuracy even for fairly small regularization parameters.
The talk is based on joint work with Christoph Brauer, Christian Clason, Paul Manns, Christian Meyer, and Benedikt Wirth."

- speaker: Jean-Michel Morel
  title: "L'analyse automatique des images et ses applications"
  abstract: "Les  images, qui il y a cinquante étaient presque toujours imprimées sur du papier ou sur une pellicule, sont en trente ans devenues digitales, et ont proliféré car avec les caméras digitales connectées, il est immédiat de les capter et de les transmettre. Ces images sont prises par les particuliers, mais aussi par tous les professionnels dans tous les secteurs de la science et de la technologie. Il n'est plus maintenant question que de les analyser automatiquement, car une analyse visuelle et manuelle est devenue impossible.  Dans cette conférence je  ferai le point sur les progrès en analyse automatique d'images, un sujet qui nous renvoie au mystère plus ancien,  et non résolu, de la définition de la perception visuelle. J'analyserai plusieurs exemples de techniques d'analyse automatiques inspirées de la théorie de la perception, tels que l'analyse automatique de la perspective dans une image, la détection d'anomalies et de falsifications, la reconnaissance des empreintes digitales, l'extraction de réseau vasculaire en  imagerie médicale, etc.  Je donnerai bien sûr  des indications sur  les théories mathématiques en jeu, parfois très récentes."

- speaker: Nicolas Papadakis
  title: "Covariant LEAst-square Re-fitting for Image Restoration"
  abstract: "In this talk, a framework to remove parts of the systematic errors affecting popular restoration algorithms is presented, with a special focus on image processing tasks. Generalizing ideas that emerged for \\( \\ell_1 \\) regularization, an approach re-fitting the results of standard methods towards the input data is developed. Total variation regularization and non-local means are special cases of interest. Important covariant information that should be preserved by the re-fitting method are identified, and the importance of preserving the Jacobian (w.r.t. the observed signal) of the original estimator is emphasized. Then, a numerical approach is proposed. It has a twicing flavor and allows re-fitting the restored signal by adding back a local affine transformation of the residual term. The benefits of the method are illustrated on numerical simulations for image restoration tasks.
This a joint work with Charles-Alban. Deledalle (CNRS), Joseph Salmon (Univ. Montpellier) and Samuel Vaiter (CNRS)."

- speaker: Fabien Pierre
  title: "Coupling variational method with CNN for image colorization"
  abstract: "Our works aim to join the powerful prediction of the convolutional neural network (CNN) with the pixel-level accuracy of variational methods. The limitations of CNN-based image colorization approaches will be described. We then focus on a CNN that is able to compute a statistical color distribution for each pixel of the image from a learning process on a large color image database. After describing its limitation, the variational method of Pierre et al. 2015 is briefly recalled. This method selects a color from a given set while regularizing the result. By combining this approach with a CNN, we have designed a fully automatic image colorization framework taht improves the accuracy in comparison to CNN alone. Some numerical experiments show the accuracy provided by our method."

- speaker: Clarice Poon
  title: "On support localisation, the Fisher metric and optimal sampling in off-the-grid sparse regularisation"
  abstract: "Sparse regularization is a central technique for both machine learning and imaging sciences. Existing performance guarantees assume a separation of the spikes based on an ad-hoc (usually Euclidean) minimum distance condition, which ignore the geometry of the problem. In this talk, we study the BLASSO (i.e. the off-the-grid version of \\( \\ell_1 \\) LASSO regularization) and show that the Fisher-Rao distance is the natural way to ensure and quantify support recovery. Under a separation imposed by this distance, I will present results which show that stable recovery of a sparse measure can be achieved when the sampling complexity is (up to log factors) linear with sparsity. On deconvolution problems, which are translation invariant, this generalizes to the multi-dimensional setting existing results of the literature. For more complex translation-varying problems, such as Laplace transform inversion, this gives the first geometry-aware guarantees for sparse recovery. This is joint work with Nicolas Keriven and Gabriel Peyre."

- speaker: Christoph Schnörr
  title: "The Assignment Flow"
  abstract: "The assignment flow is a dynamical system that evolves on an elementary statistical manifold and performs image labeling, i.e.~context-sensitive image classification. It provides a smooth and computationally efficient alternative to non-smooth discrete graphical models and enables to study basic problems related to the design of larger systems for image analysis: supervised labeling, unsupervised label learning and learning using optimal control. The talk reports the mathematical ingredients (information theory, discrete optimal transport, geometric integration), recent results and perspectives."
  
- speaker: Carola Schoenlieb
  title: "A geometric integration approach to non-smooth and non-convex optimisation"
  abstract: "The optimisation of nonsmooth, nonconvex functions without access to gradients is a particularly challenging problem that is frequently encountered, for example in model parameter optimisation problems. Bilevel optimisation of parameters is a standard setting in areas such as variational regularisation problems and supervised machine learning. We present efficient and robust derivative-free methods called randomised Itoh--Abe methods. These are generalisations of the Itoh--Abe discrete gradient method, a well-known scheme from geometric integration, which has previously only been considered in the smooth setting. We demonstrate that the method and its favourable energy dissipation properties are well-defined in the nonsmooth setting. Furthermore, we prove that whenever the objective function is locally Lipschitz continuous, the iterates almost surely converge to a connected set of Clarke stationary points. We present an implementation of the methods, and apply it to various test problems. The numerical results indicate that the randomised Itoh--Abe methods are superior to state-of-the-art derivative-free optimisation methods in solving nonsmooth problems while remaining competitive in terms of efficiency. If time allows we will also give some results in the smooth setting where we could derive convergence rates. This is joint work with Erlend Riis, Matthias Ehrhardt, Torbjørn Ringholm and Reinout Quispel."

- speaker: Gabriele Steidl
  title: "Vector-valued optimal Lipschitz extensions on finite graphs"
  abstract: "Let \\( G := (V,E,w) \\) be an undirected connected weighted graph with weight function \\( w : E \\to [0,1] \\) and \\( \\emptyset \\neq U \\subseteq V \\), where \\( (u,v) \\not \\in E \\) if \\( u,v \\in U \\). 
  We deal with minimizers of the functionals 
  \\[ E_{p} f:= \\sum_{u \\in V} \\Big( \\sum_{v \\sim u} w(u,v)^p |f(u) - f(v)|^p \\Big), \\]
  \\[E_{\\infty} f:=\\max_{u \\in V} \\left(\\max_{v \\sim u} w(u,v) |f(u) - f(v)| \\right) \\]
  subject to \\( f|_U = g \\) for vector-valued functions \\( f \\) and address their relation to midrange filters and \\( p \\)-Laplacians. Joint work with M. Bacak, J. Hertrich and S. Neumayer."
 
- speaker: Hugues Talbot 
  title: "Discrete multigrid convergent estimators of curvature"
  abstract: "Recent works have indicated the potential of using curvature as a regularizer in image segmentation, in particular for the class of thin and elongated objects. These are ubiquitous in bio-medical imaging (e.g. vascular networks), in which length regularization can sometime performs badly, as well as in texture identication. However, curvature is a second-order dierential measure, and so its estimators are sensitive to noise. The straightforward extentions to Total Variation are not convex, making it a challenge to optimize. State-of-art techniques make use of a coarse approximation of curvature that limit practical applications. We argue that curvature must instead be computed using a multigrid convergent estimator, and we propose in this paper a new digital curvature ow which mimicks continuous curvature flow. We illustrate its potential as a post-processing step to a variational segmentation framework."

- speaker: Yves van Gennip
  title: "Variational methods on graphs with applications in imaging and data classification"
  abstract: "Applications that can be described by variational models profit from all the advantages those models bring along. Both on the functional level as on the level of the associated differential equations, powerful techniques have been developed over the years to study these models. Up until fairly recently, such models were typically formulated  in a continuum setting, i.e. as the minimization of a functional over an admissible class of functions whose domains are subsets of Euclidean space or Riemannian manifolds. The field of variational methods and partial differential equations (PDEs) on graphs aims to harness the power of variational methods and PDEs to tackle problems that inherently have a graph (network) structure. In this talk we will encounter the graph Ginzburg--Landau model, which is a paradigmatic example of a variational model on graphs. Just as its continuum forebear is used to model phase separation on a continuum domain ---it assigns to each point of the domain a value from an (approximately) discrete set of values--- the graph Ginzburg--Landau model describes phase separation on the nodes of a graph. This makes it extremely well suited for applications such as data clustering, data classification, community detection in networks, and image segmentation. Theoretically there are also interesting questions to ask, often driven by the properties that have already been established for the continuum Ginzburg--Landau model, such as Gamma-convergence properties of the functional and relationships between its associated differential equations. This presentation will give an overview of some recent developments."

- speaker: Thomas Veit
  title: "Image processing and computer vision at GoPro"
  abstract: "GoPro frees people to celebrate the moment, inspiring others to do the same. From cameras to apps and accessories, everything we do is geared to help you capture life as you live it, share the experience and pass on the stoke. 
What started with a 35mm camera and a wrist strap made from old wetsuits and plastic scraps has grown into an international company that has sold over 26 million GoPro cameras in more than 100 countries. This talk will give you a brief overview of the activities at GoPro Paris in the field of Image Processing and Computer Vision, among which : Image Signal Processor (ISP) design, Camera Controls (Auto-Exposure, Auto-White Balance), Video stabilization, Object tracking, High Dynamic Range imaging, Scene understanding, Automatic video editing and stitching for 360 video."

- speaker: Luca Zanni
  title: "Spectral properties of steplength selections in gradient methods: from unconstrained to constrained optimization"
  abstract: "The steplength selection strategies have a remarkable effect on the efficiency of gradient-based methods for both unconstrained and constrained optimization. In the last years, many challenging optimization problems arising from different domains of applied sciences, such as imaging and machine learning, have been successfully faced with first-order approaches thanks to the design of new adaptive steplength rules. A crucial aspect at the basis of these new rules is the ability to capture low-cost second-order information by exploiting special relationship between the steplengths and the spectrum of the Hessian of the objective function. In this talk, starting from a spectral analysis of popular steplength rules in unconstrained optimization, we introduce some ideas for exploiting the steplength spectral properties in case of gradient projection approaches for box-constrained problems. This study suggests how state of the art steplength rules need to be modified for taking into account the presence of box-constraints. Furthermore, the combination of the new rules with variable metric strategies is also discussed. Numerical results on both randomly generated test problems and imaging applications are reported for evaluating the behaviour of the considered steplengths within gradient projection methods. This is a joint work with S. Crisci, F. Porta and V. Ruggiero."
  
  
