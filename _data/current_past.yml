- speaker: Samuel Hurault
  date: December 2nd
  time: 2pm
  affiliation: CNRS, LIGM
  url: https://samuelhurault.netlify.app/
  title: "From Score Matching to Diffusion: a fine-grained error analysis in the Gaussian setting"
  abstract: "Sampling from an unknown distribution, accessible only through discrete samples, is a fundamental problem at the core of generative AI. The current state-of-the-art methods follow a two-step process: first, estimating the score function (the gradient of a smoothed log-distribution) and then applying a diffusion-based sampling algorithm. The resulting distribution's correctness can be impacted by three major factors: the generalization and optimization errors in score matching, and the discretization error in the diffusion. In this paper we provide, in the Gaussian setting, the exact Wasserstein sampling error that arises from these four error sources. This allows us to rigorously track how the anisotropy of the data distribution (encoded by its power spectrum) interacts with key parameters of the end-to-end sampling method."
  room: Room Yvette Cauchoix (Perrin building)
  
- speaker: Nils Laurent
  date: December 2nd
  time: 3pm
  affiliation: LASPI Roanne
  url: https://nils-laurent.github.io/
  title: "Restauration d'Images par Algorithme Plug-and-Play Multiniveaux"
  abstract: "Les algorithmes de reconstruction d'images Plug-and-Play (PnP) sont fondés sur des réseaux de neurones profonds débruiteurs et utilisés comme a priori pour la résolution de problèmes inverses. Malgré leur flexibilité, les algorithmes PnP requièrent un large nombre d'itérations pour converger et leur performance est sensible au choix de l'initialisation et des hyperparamètres. Dans cette présentation, nous considérons un nouvel algorithme PnP multiniveaux qui accélère la convergence en combinant des itérations faites à différentes échelles et améliore la robustesse à l'initialisation ainsi qu'aux hyperparamètres grâce à une stratégie exploitant les échelles plus grossières pour la résolution aux échelles fines. Nous pourrons observer par une série d'expériences numériques incluant le dématriçage et l'inpainting que cette nouvelle méthode est plus rapide et donne de meilleures reconstructions que d'autres algorithmes PnP états-de-l'art."
  room: Room Yvette Cauchoix (Perrin building)


- speaker: Kimia Nadjahi
  date: November 4th
  time: 2pm
  affiliation: CNRS, ENS PARIS
  url: https://kimiandj.github.io/
  title: "Optimal Transport-based Conformal Prediction"
  abstract: "Conformal Prediction (CP) is a principled framework for quantifying uncertainty in blackbox learning models, by constructing prediction sets with finite-sample coverage guarantees. Traditional approaches rely on scalar nonconformity scores, which fail to fully exploit the geometric structure of multivariate outputs, such as in multi-output regression or multiclass classification. Recent methods addressing this limitation impose predefined convex shapes for the prediction sets, potentially misaligning with the intrinsic data geometry. We introduce a novel CP procedure handling multivariate score functions through the lens of optimal transport. Specifically, we leverage Monge-Kantorovich vector ranks and quantiles to construct prediction regions with flexible, potentially non-convex shapes, better suited to the complex uncertainty patterns encountered in multivariate learning tasks. We prove that our approach ensures finite-sample, distribution-free coverage properties, similar to typical CP methods. We then adapt our method for multi-output regression and multiclass classification, and also propose simple adjustments to generate adaptive prediction regions with asymptotic conditional coverage guarantees. Finally, we evaluate our method on practical regression and classification problems, illustrating its advantages in terms of (conditional) coverage and efficiency. This is joint work with Gauthier Thurin (CNRS, ENS Paris) and Claire Boyer (Université Paris-Saclay)."
  room: Amphi Darboux (Borel building)

- speaker: Laetitia Chapel 
  date: November 4th
  time: 3pm
  affiliation: Institut Agro Rennes-Angers, IRISA
  url: https://people.irisa.fr/Laetitia.Chapel/
  title: "Sliced optimal transport plans with an application to conditional flow matching"
  abstract: "Optimal Transport (OT) has emerged as a fundamental tool in modern machine learning, mainly due to its ability to provide meaningful comparisons between probability distributions. One of the key strengths of OT is its dual nature: it not only introduces a mathematically rigorous framework defining Wasserstein distances but also constructs an optimal coupling (or transport plan) between distributions. This coupling reveals explicit correspondences between samples, enabling a broad spectrum of applications. Despite the numerous successes of optimal transport in machine learning and the availability of many tools to approximate Wasserstein distances, computing OT plans remains computationally challenging. 
In this talk, I will present a new methodology to efficiently approximate sliced OT plans. The formulation can be recast as a bilevel optimization problem, and I will propose a differentiable generalized approximation that can be further adapted to data residing on manifolds. Finally, I will demonstrate the practical value of this approach by introducing a novel sliced OT-based conditional flow matching method for image generation, an application where fast computation of transport plans is crucial."
  room: Amphi Darboux (Borel building)
  
- speaker: Raphaël Achddou
  date: October 7th
  time: 2pm
  affiliation: ESIEE Paris, LIGM
  url: 
  title: "Synthetic training of deep image restoration networks : principles and applications"
  abstract: " Neural Networks have surpassed traditional prior-based approaches in solving inverse problems, but their black-box nature hinders their interpretability and confidence. To address these issues, a potential approach is to synthesize training images with controlled statistical properties. 
In this talk, I’ll present how a simple occlusion-based image model called the Dead Leaves model can be used to generate high-quality training data for various image restoration tasks. I’ll then show how this model can be adapted to incorporate essential image properties like texture, depth, and complex object geometry. The resulting trained restoration models perform similarly to those trained on real images while offering additional benefits, such as insightful ablation studies, inherent invariance properties, and faster convergence, which I’ll discuss further."
  room: Room Pierre Grisvard (Borel building)


