- speaker: Stéphanie Allassonnière
  title: "Mixed-effect model for the spatiotemporal analysis of longitudinal manifold-valued data"
  abstract: "In this talk, I propose to present a generic hierarchical spatiotemporal model for longitudinal manifold-valued data, which consists in repeated measurements over time for a group of individuals. This model allows us to estimate a group-average trajectory of evolution, considered as a piece-wise geodesic of a given Riemannian manifold. Individual trajectories of progression are obtained as random variations, which consist in parallel shifting and time reparametrization, of the average trajectory. These spatiotemporal transformations allow us to characterize changes in the direction and in the pace at which trajectories are followed. We propose to estimate the parameters of the model using a stochastic version of the expectation-maximization (EM) algorithm, the Monte Carlo Markov Chain Stochastic Approximation EM (MCMC SAEM) algorithm with tempering schemes. 
This generic spatiotemporal model is used to analyze the temporal progression of a family of biomarkers. This progression model estimates a normative scenario of the progressive impairments of several cognitive functions, considered here as biomarkers, during the course of Alzheimer’s disease. We also used this model to understand the response to antiangiogenic treatment in metastatic cancers." 

- speaker: Marie-Paule Cani
  title: "Création des mondes virtuels : Objets auto-similaires et distributions d'éléments"
  abstract: "Les objets naturels, d'un arbre isolé à une montagne rocheuse partiellement couverte de végétation, se caractérisent par leur multitude de détails, souvent similaires mais chacun différent. Reproduire cette complexité est un véritable défi pour les créateurs des mondes virtuels - comme par exemple les mondes que vous découvrez dans les jeux vidéo ou les films et effets spéciaux 3D. Ils  s'agit en effet de permettre un bon contrôle du résultat au créateur tout en automatisant au maximum les tâches répétitives (comme celle consistant à placer successivement chaque touffe d'herbe). Dans l'idéal, un bon système de création offre également une aide au réalisme, par le maintien de certaines contraintes (par exemple, un arbre poussera difficilement au milieu d'une falaise). Cet exposé met l'accent sur les avancées récentes en informatique graphique, qui s'appuient sur des outils statistiques  pour résoudre ces problèmes. Nous verrons comment la création des mondes virtuels peut être rendue plus expressive en combinant un contrôle utilisateur simple, via des croquis 2D ou des mini-exemples de groupes d''éléments, avec l'apprentissage statistique et la synthèse de distributions aléatoires, respectant des lois précises."

- speaker: Xavier Descombes
  title: "Multiple objects detection in biological images using a Marked Point Process Framework"
  abstract: "The marked point process framework has been successfully developed in the field of image analysis to detect a configuration of predefined objects. In this talk I will show how it can be particularly applied to biological imagery. We present a simple model that shows how some of the challenges specific to biological data are well addressed by the methodology. I will describe an extension to this first model to address other challenges due, for example, to the shape variability in biological material. The results  illustrate the MPP framework using the 'simcep' algorithm for simulating populations of cells."


- speaker: Remco Duits
  title: "PDEs on the Homogeneous Space of Positions and Orientations"
  abstract: "A link to the abstract is provided above in the program." 

- speaker: Alfred Hero
  title: "TeraLasso for sparse time-varying image modeling"
  abstract: "We propose a new ultrasparse graphical model for representing time varying images, and other multiway data,  based on a Kronecker sum representation of the spatio-temporal inverse covariance matrix. This statistical model decomposes the inverse covariance into a linear Kronecker sum representation with sparse Kronecker factors. Under the assumption that the multiway observations are matrix-normal the l1 sparsity regularized log-likelihood function is convex and admits significantly faster statistical rates of convergence than other sparse matrix normal algorithms such as graphical lasso or Kronecker graphical lasso. We will illustrate the method on meteoroligical and MRI imagery to demonstrate the ability of the model to capture sparse structure  with few samples. This is joint work with Kristjan Greenewald and Shuheng Zhou."


- speaker: Ron Kimmel
  title: "Interaction between invariant structures for shape analysis."
  abstract: "A classical approach for surface classification is to find a compact algebraic representation for each surface that would be similar for objects within the same class and preserve dissimilarities between classes. Self functional maps was suggested by Halimi and the lecturer as a surface representation that satisfies these properties, translating the geometric problem of surface classification into an algebraic form of classifying matrices. The proposed map transforms a given surface into a universal isometry invariant form defined by a unique matrix. The suggested representation is realized by applying the functional maps framework to map the surface into itself. The idea is to use two different metric spaces of the same surface for which the functional map serves as a signature. As an example we suggested the regular and the scale invariant surface laplacian operators to construct two families of eigenfunctions. The result is a matrix that encodes the interaction between the eigenfunctions resulted from two different Riemannian manifolds of the same surface. Using this representation, geometric shape similarity is converted into algebraic distances between matrices. If time permits, I will also comment on some of our efforts to migrate geometry into the arena of deep learning, in a sense learning to understand." 

- speaker: Michael Lindenbaum
  title: "Using statistics to justify vision algorithms"
  abstract: "Many successful vision algorithms are based on clever heuristics. We study two algorithms and show that, under certain statistical models, they correspond to common statistical decisions. The first is the local variation (LV) algorithm (LV) (Efficient graph-based image segmentation, by Felzenszwalb and  Huttenlocher). We show that algorithms similar to LV can be devised by applying different statistical models and decisions, some of which are based on statistics of natural images and on a hypothesis testing decision. We we denote these algorithms probabilistic local variation (pLV). We then turn to the SIFT matching algorithm (Object recognition from local scale-invariant features, by Lowe). Here we study the ratio criterion and show that this criterion could be a result of using various statistical decisions and, in particular, could correspond to minimizing the conditional probability of a false match. In both cases, the analysis provides further theoretical justification and well-founded explanations for the unexpected high performance of these two algorithms. It also provides statistically based versions of these algorithms that are at least as good as, and sometimes better than, the originals. Joint work with Michael Baltaxe, Peter Meer, Avi Kaplan, and Tammy Avraham."

- speaker: Sylvain Paris
  title: "Photography Made Easy"
  abstract: "With digital cameras and smartphones, taking a picture has become effortless and easy. Autofocus and autoexposure ensure that all photos are sharp and properly exposed. However, this is not sufficient to get great photos. Most pictures need to be retouched to become aesthetically pleasing. This step still requires a great deal of expertise and a lot of time when done with existing tools. Over the years, I have dedicated a large part of my research to improving this situation. In this talk, I will present a few recent results where we use existing photos by artists as models to make ordinary pictures look better. I will also discuss the algorithmic and statistical underpinnings of these results."

- speaker: Marcelo Pereyra
  title: "Bayesian inference and convex geometry: theory, methods, and algorithms"
  abstract: "This talk summarises some new developments in theory, methods, and algorithms for performing Bayesian inference in high-dimensional models that are log-concave, with application to mathematical and computational imaging in convex settings. These include new efficient stochastic simulation and optimisation Bayesian computation methods that tightly combine proximal convex optimisation with Markov chain Monte Carlo techniques; strategies for estimating unknown model parameters and performing model selection; and methods for calculating Bayesian confidence intervals for images and performing uncertainty quantification analyses; all illustrated with a range of mathematical imaging experiments." 

- speaker: Julien Rabin 
  title: "Detecting Overfitting of Deep Generative Networks via Latent Recovery"
  abstract: "(Joint work with Ryan Webster,  Loic Simon, Frederic Jurie).
State of the art deep generative networks are capable of producing images with such incredible realism that they can be suspected of memorizing training images. It is why it is not uncommon to include visualizations of training set nearest neighbors, to suggest generated images are not simply memorized. We demonstrate this is not sufficient and motivates the need to study memorization/overfitting of deep generators with more scrutiny. This work addresses this question by i) showing how simple losses are highly effective at reconstructing images for deep generators ii) analyzing the statistics of reconstruction errors when reconstructing training and validation images, which is the standard way to analyze overfitting in machine learning. Using this methodology, we show that overfitting is not detectable in the pure GAN models proposed in the literature, in contrast with those using hybrid adversarial losses, which are amongst the most widely applied generative methods. We also show that standard GAN evaluation metrics fail to capture memorization for some deep generators. Finally, experiment shows how off-the-shelf GAN generators can be successfully applied to face inpainting and face super-resolution using the proposed reconstruction method, without hybrid adversarial losses."


- speaker: Anuj Srivastava
  title: "Functional Data Analysis Under Shape Constraints"
  abstract: "(Joint work with Sutanoy Dasgupta, Ian Jermyn, and Debdeep Pati).
We consider a subarea of functional data analysis, where functions of interest are constrained to have pre-determined shape classes. The notion of shape is quite flexible. It can mean a fixed number of modes in the function, say a bimodal or a trimodal function, or the number of modes plus a vector of function heights at the modes. The locations of these modes are left as variables, in order to fit to the data. The basic idea is to define a set of valid functions (with the desired shape constraints) and to solve optimization problems (such as  maximum likelihood estimation) on this set. This set is established using the 'deformable template' theory -- choose a function from the correct class and use an appropriate action of the diffeomorphism group to form its orbits. Orbits define shape classes. The larger picture is to learn shape classes from the training data, and then to impose learnt shape constraints in estimating future functions from sparse, noisy data. We present some examples of this framework. First, we introduce the problem of density estimation under arbitrary multimodal shape constraints. While unimodal density estimation is often studied in the literature, there are no general estimators for the multimodal case. Second, we provide a study involving daily electricity consumption data at household level (in Tallahassee, FL) where certain shapes dominate the data."


- speaker: Michael Unser
  title: "Hybrid sparse stochastic processes and the resolution of linear inverse problems"
  abstract: "Sparse stochastic processes are continuous-domain processes that are specified as solutions of linear stochastic differential equations driven by white Lévy noise. These processes admit a parsimonious representation in some matched wavelet-like basis. Such models are relevant for image compression, compressed sensing, and, more generally, for the derivation of statistical algorithms for solving ill-posed inverse problems.
The hybrid processes of this talk are formed by taking a sum of such elementary processes plus an optional Gaussian component. We apply this hybrid model to the derivation of image reconstruction algorithms from noisy linear measurements. In particular, we derive a hybrid MAP estimator, which is able to successfully reconstruct signals, while identifying the underlying signal components. Our scheme is compatible with classical Tikhonov and total-variation regularization, which are both recovered as limit cases. We present an efficient ADMM implementation and illustrate the advantages of the hybrid model with concrete examples."