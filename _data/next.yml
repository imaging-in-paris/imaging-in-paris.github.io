

- speaker: Rémi Gribonval
  date: 8 november 2018
  time: 14h-15h
  room: "235A, 29 rue de l'Ulm"
  affiliation: INRIA, Panama project-team
  url: http://people.irisa.fr/Remi.Gribonval/
  title: "Approximation with sparsely connected deep networks"
  abstract: "Many of the data analysis and processing pipelines that have been carefully engineered by generations of mathematicians and practitioners can in fact be implemented as deep networks. Allowing the parameters of these networks to be automatically trained (or even randomized) allows to revisit certain classical constructions.

The talk first describes an empirical approach to approximate a given matrix by a fast linear transform through numerical optimization. The main idea is to write fast linear transforms as products of few sparse factors, and to iteratively optimize over the factors. This corresponds to training a sparsely connected, linear, deep neural network. Learning algorithms exploiting iterative hard-thresholding  have been shown to perform well in practice, a striking example being their ability to somehow “reverse engineer” the fast Hadamard transform. Yet, developing a solid understanding of their conditions of success remains an open challenge.

In a second part, we study the expressivity of sparsely connected deep networks. Measuring a network's complexity by its number of connections, we consider the class of functions which error of best approximation with networks of a given complexity decays at a certain rate. Using classical approximation theory, we show that this class can be endowed with a norm that makes it a nice function space, called approximation space. We establish that the presence of certain “skip connections” has no impact of the approximation space, and discuss the role of the network's nonlinearity (also known as activation function) on the resulting spaces, as well as the benefits of depth.  
For the popular ReLU nonlinearity (as well as its powers), we relate the newly identified spaces to classical Besov spaces, which have a long history as image models associated to sparse wavelet decompositions. The sharp embeddings that we establish highlight how depth enables sparsely connected networks to approximate functions of increased “roughness” (decreased Besov smoothness) compared to shallow networks and wavelets.

Joint work with Luc Le Magoarou (Inria), Gitta Kutyniok (TU Berlin), Morten Nielsen (Aalborg University) and Felix Voigtlaender (KU Eichstätt). "

- speaker: Antoine Houdard
  date: 8 november 2018
  time: 15h-16h
  room: "235A, 29 rue de l'Ulm"
  affiliation: "Telecom ParisTech & Universite Paris Descartes"
  url: https://houdard.wp.imt.fr
  title: "Some advances in patch-based image denoising"
  abstract: "In this talk I will present my PhD thesis work on non-local methods for image processing, and their application to various tasks such as denoising. Natural images contain redundant structures, and this property can be used for restoration purposes. A common way to consider this self-similarity is to separate the image into patches. These patches can then be grouped, compared and filtered together. The main part of this talk will be dedicated to the study of Gaussian priors for patch-based image denoising. Such priors are widely used for image restoration. We propose some ideas to answer the following questions: Why are Gaussian priors so widely used? What information do they encode about the image? Next I shall propose a probabilistic high-dimensional mixture model on the noisy patches. This model adopts a sparse modeling which assumes that the data lie on group-specific subspaces of low dimensionalities. This yields a denoising algorithm that demonstrates state-of-the-art performance.  The last part of the talk explores different ways of aggregating the patches together. A framework that expresses the patch aggregation in the form of a least squares problem is proposed."


- speaker: Hughes Talbot
  date: 6 december 2018
  time: 14h-15h
  room: 314
  affiliation: CentraleSupelec
  url: https://hugues-talbot.github.io/
  title: ""

- speaker: Denis Fortun
  date: 6 december 2018
  time: 15h-16h
  room: 314
  affiliation: iCUBE, CNRS, Université de Strasbourg
  url: http://bigwww.epfl.ch/fortun/index.html
  title: ""
