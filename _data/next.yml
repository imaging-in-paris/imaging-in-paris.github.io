
- speaker: Emre Baspinar
  date: 15 December 2022
  time: 14h-15h
  affiliation: CNRS-NeuroPSI, Laboratory of Computational Neuroscience
  url: https://sites.google.com/site/emrebaspinarhomepage/home?pli=1
  title: A sub-Riemannian cortical model with frequency-phase and its application to image processing
  abstract: In this talk, we will see a new geometrical model of the primary visual cortex together with its application to image enhancement and completion. Our departure point is the visual cortex model of the orientation selective cortical neurons, which was presented in [1]. We spatially extend this model to a five dimensional sub-Riemannian geometry and provide a novel geometric framework of the mammalian visual cortex which models orientation-frequency selective, phase shifted cortical cell behavior and the associated neural connectivity. The model extracts orientation, spatial frequency and phase information of the objects in any given two dimensional input image. Such information provides a characterization of the object boundaries and textures in the input image. We provide an image enhancement algorithm based on multi-frequency Laplace-Beltrami flow in the sub-Riemannian framework of the model. This algorithm can be modified so as to be used for image completion as well.
- speaker: Dario Prandi
  date: 15 December 2022
  time: 14h-15h
  affiliation: Université Paris Saclay, Centrale-Supélec
  url: https://dprn.github.io/
  title: Reproducing sensory induced visual hallucinations via neural fields
  abstract: Understanding the interaction between retinal stimulation and the cortical response in the primary visual cortex (V1 for short) is a significant challenge in improving our insight into human perception and visual organisation. In this talk we will present recent work on the reproduction of various visual illusions via continuous neural field models. In particular, we will present recent results in collaboration with Y. Chitour and C. Tamekue on the modelling via Wilson-Cowan equations of MacKay-type effects (i.e., phantom images induced by geometric patterns), showing that while the classical MacKay effect (Nature, 1957) can be recovered via a linear model, the experiences of Billock and Tsou (PNAS, 2007) are fundamentally due to the presence of a non-linearity
- speaker: Jonathan Vacher
  date: 13 Octobre 2022
  time: 14h-15h
  room: salle Grisvard (314)
  affiliation: MAP5, Université Paris-Cité
  url:  https://jonathanvacher.github.io/
  title: "Measuring uncertainty in human visual segmentation"
  abstract: "Segmenting visual inputs into distinct groups of features and visual objects is central to visual function. Traditional psychophysics uncovered many rules of human perceptual segmentation, and progress in machine learning produced successful algorithms. Yet, the computational logic of human segmentation remains unclear, because we lack well-controlled paradigms to measure perceptual segmentation maps and compare models quantitatively. Here we propose a new, integrated approach: given an image, we measure multiple same--different judgments and perform model--based reconstruction of the underlying segmentation map. The reconstruction is robust to several experimental manipulations and captures the variability of individual participants. We demonstrate the approach on human segmentation of natural images and composite textures, and we show that image uncertainty affects measured human variability as well as how participants weigh different visual features. Because any segmentation algorithm can be plugged in to perform the reconstruction, our paradigm affords quantitative tests of theories of perception as well as new benchmarks for segmentation algorithms."
- speaker: Isabelle Bloch
  date:  13 Octobre 2022
  time: 15h-16h
  room: salle Grisvard (314)
  affiliation: LIP6 - Sorbonne Université
  url: https://www.lip6.fr/actualite/personnes-fiche.php?ident=P1486
  title: "Hybrid AI for knowledge representation and model-based medical image understanding - Towards explainability"
  abstract: "This presentation will focus on hybrid AI, as a step towards explainability, more specifically in the domain of spatial reasoning and image understanding. Image understanding benefits from the modeling of knowledge about both the scene observed and the objects it contains as well as their relationships. We show in this context the contribution of hybrid artificial intelligence, combining different types of formalisms and methods, and combining knowledge with data. Knowledge representation may rely on symbolic and qualitative approaches, as well as semi-qualitative ones to account for their imprecision or vagueness. Structural information can be modeled in several formalisms, such as graphs, ontologies, logical knowledge bases, or neural networks, on which reasoning will be based. Image understanding is then expressed as a problem of spatial reasoning. These approaches will be illustrated with examples in medical imaging, illustrating the usefulness of combining several approaches."
