
- speaker: Éloi Tanguy 
  date: May 21st 2024
  time: TBA
  affiliation: MAP5, Université Paris Cité
  url: https://eloitanguy.github.io/
  title: "Properties of Discrete Sliced Wasserstein Losses"
  abstract: "The Sliced Wasserstein (SW) distance has become a common alternative to the Wasserstein distance for the comparison of probability measures. Widespread applications include image processing, domain adaptation and generative modelling, where it is typical to optimise some parameters in order to minimise SW, which in practice serves as a loss function between discrete probability measures. These optimisation problems all bear the same sub-problem, which is minimising the SW distance between two uniform discrete measures with the same amount of points as a function of the support (i.e. a matrix of data points) of one of the measures. We study the regularity and optimisation properties of this energy, as well as its Monte-Carlo approximation (estimating the expectation in SW using projection samples), as well as asymptotical and non-asymptotical statistical properties of the Monte-Carlo approximation. Finally, we show that in a certain sense, Stochastic Gradient Descent methods minimising these energies converge towards (Clarke) critical points, with an extension to Generative Neural Network training."
  room: 201 (Maryam Mirzakhani)
  
- speaker: Anton François
  date: June 4th 2024
  time: TBA
  affiliation: Centre Borelli, ENS Paris-Saclay
  url: https://antonfrancois.github.io/
  title: "TBA"
  abstract: "TBA"
  room: 314 (Pierre Grisvard)
  
- speaker: Shizhe Chen
  date: June 4th 2024
  time: 14h
  affiliation: WILLOW, INRIA Paris
  url: https://cshizhe.github.io/
  title: "Vision and language pre-training for robot navigation and manipulation"
  abstract: "Pre-training on large-scale datasets has significantly accelerated progress in various domains. However, collecting real robot data for pre-training remains expensive and lacks scalability. In this talk, I will demonstrate how we can leverage large-scale Internet data to enhance robot learning. Specifically, I will first present pre-training for vision-and-language navigation, where we take advantage of in-domain web image-captions and unlabeled 3D houses to improve models’ generalization capabilities in unseen environments. Next, I will delve into pre-training approaches for more complex robot manipulation which requires fine-grained visual perception and precise control. I will introduce a versatile pre-training framework based on web 3D objects to improve visual perception for robots."
  room: 314 (Pierre Grisvard)

