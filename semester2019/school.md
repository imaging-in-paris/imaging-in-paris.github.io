---
layout: page
title: "The mathematics of imaging: the CIRM pre-school"
description: "7-11 January 2019"
header-img: "../img/sugiton.jpg"
---

This Winter school is intended to be a pre-school for the  [thematic trimester](https://imaging-in-paris.github.io) "The mathematics of Imaging", that will be held in Paris at the IHP (Institut Henri Poincaré), from January 7 to April 5, 2019.

This pre-school will take place at the [CIRM](http://www.cirm-math.fr/) (Centre International de Rencontres Mathématiques), Marseille, the week January 7-11, 2019.

Pre-registration
-------------

You can pre-register on the [CIRM website of the school](https://conferences.cirm-math.fr/1993.html).

Program of the school
-------------

The pre-school will contain courses, practical sessions, flash presentations and poster sessions.

The 4 main courses will be:
- [Daniel Cremers](https://vision.in.tum.de/members/cremers) (München), _convex methods in imaging_
- [Alexandre Gramfort](http://alexandre.gramfort.net/) (INRIA),  _practical machine learning_
- [Marcelo Pereyra](http://www.macs.hw.ac.uk/~mp71/) (Heriot-Watt): _Bayesian methods in imaging_. **SLIDES**: [Slides Part I](./slides/Pereyra_Presentation_CIRM_I_Jan_2019.pdf), [Slides Part II](./slides/Pereyra_Presentation_CIRM_II_Jan_2019.pdf), [Slides Part III](./slides/Pereyra_Presentation_CIRM_III_Jan_2019.pdf), [Slides Part IV](./slides/Pereyra_Presentation_CIRM_IV_Jan_2019.pdf)
- [Clarice Poon](http://www.damtp.cam.ac.uk/user/cmhsp2/) (Cambridge): _sparsity in imaging_

Agenda
-------------

MONDAY

- 9h00-10h30 - Sparsity in imaging
- 10h30-11h - Coffee break
- 11h-12h30 - Sparsity in imaging
- 12h30-14h - Lunch
- 14h-15h30 - Variational methods and convex relaxation for Computer Vision
- 15h30-16h - Coffee break
- 16h00-17h30 - Variational methods and convex relaxation for Computer Vision
- 18h00-19h00 - Flash presentations session
- Evening 

TUESDAY

- 9h00-10h30 - Variational methods and convex relaxation for Computer Vision
- 10h30-11h - Coffee break
- 11h-12h30 - Variational methods and convex relaxation for Computer Vision
- 12h30-14h - Lunch
- 14h-15h30 - Sparsity in imaging
- 15h30-16h - Coffee break
- 16h00-17h30 - Sparsity in imaging
- 18h00-19h00 - Poster session 
- Evening 

WEDNESDAY

- 9h00-10h30 - Bayesian methods in imaging
- 10h30-11h - Coffee break
- 11h-12h30 - Bayesian methods in imaging
- 12h30-14h - Lunch
- Free afternoon
- Evening 

THURSDAY

- 9h00-10h30 - Bayesian methods in imaging
- 10h30-11h - Coffee break
- 11h-12h30 - Bayesian methods in imaging
- 12h30-14h - Lunch
- 14h-15h30 - Practical machine learning
- 15h30-16h - Coffee break
- 16h00 -17h30 - Practical machine learning
- Evening - Bouillabaisse diner

FRIDAY
- 9h00-10h30 - Practical machine learning
- 10h30-11h - Coffee break
- 11h-12h30 - Practical machine learning
- 12h30-14h - Lunch


Abstracts
------

[Daniel Cremers](https://vision.in.tum.de/members/cremers) (Technische Universität München), _Variational methods and convex relaxation for Computer Vision_:
Variational methods are among the most classical and established methods to solve a multitude of problems arising in computer vision, image processing and beyond.  My presentation covers four parts: First, I will introduce the basic concepts of variational
methods and present a number of examples.  Second, I will show how respective energies can be derived from the principle of Bayesian
inference.  Third, I will discuss techniques of convex relaxation and functional lifting which allow us to compute globally optimal or
near-optimal solutions to certain non-convex energy minimization problems.  And lastly, I will present variational methods for 3d
reconstruction and visual SLAM (simultaneous localization and mapping). If time permits, I will talk about convex relaxations for elastic shape matching. 

[Clarice Poon](http://www.damtp.cam.ac.uk/user/cmhsp2/) (University of Cambridge): _Sparsity in imaging_:
In the last few decades sparsity has become ubiquitous and is often one of the key assumptions behind imaging methods. In this course, we will discuss how sparsity arises in imaging (in particular, wavelets) and some ways in which sparsity has been exploited (in particular, compressed sensing and super resolution of measures).

[Marcelo Pereyra](http://www.macs.hw.ac.uk/~mp71/) (Heriot-Watt University, Edinburgh): _Bayesian methods in imaging_: This course presents an overview of modern Bayesian strategies for solving imaging inverse problems. We will start by introducing the Bayesian statistical decision theory framework underpinning Bayesian analysis, and then explore efficient numerical methods for performing Bayesian computation in large-scale settings. We will pay special attention to high-dimensional imaging models that are log-concave w.r.t. the unknown image, related to so-called "convex imaging problems". This will provide an opportunity to establish connections with the convex optimisation and machine learning approaches to imaging, and to discuss some of their relative strengths and drawbacks. Examples of topics covered in the course include: efficient stochastic simulation and optimisation numerical methods that tightly combine proximal convex optimisation with Markov chain Monte Carlo techniques; strategies for estimating unknown model parameters and performing model selection, methods for calculating Bayesian confidence intervals for images and performing uncertainty quantification analyses; and new theory regarding the role of convexity in maximum-a-posteriori and minimum-mean-square-error estimation. The theory, methods, and algorithms are illustrated with a range of mathematical imaging experiments.

[Alexandre Gramfort](http://alexandre.gramfort.net/) (INRIA, Parietal Team, Université Paris-Saclay),  _Practical machine learning_: What you will learn in this course:
	
- What is formally statistical machine learning and the theory of risk
minimization.
- How to setup a machine learning problem. Hands on: Case study
- How to learn with gradient descent. Hands on: Logistic regression
with Numpy or PyTorch.
- How to learn with (boosted) trees and forests. Hands on: AdaBoost
and Gradient Boosting from scratch.
- How to automate model search and hyperparameter selection. Hands on:
Grid search, Random Search and Bayesian Optimization
- How to use learning curves to learn about your data.

I will present along this course examples of applications in the field of neuroimaging and neuroscience.

Scientific Committee
-----

- [Jean-François Aujol](https://www.math.u-bordeaux.fr/~jaujol/) (Bordeaux).
- [Martin Burger](https://www.uni-muenster.de/AMM/num/Arbeitsgruppen/ag_burger/organization/burger/) (Münster)
- [Julie Delon](https://delon.wp.mines-telecom.fr/) (Paris 5)
- [Agnès Desolneux](http://desolneux.perso.math.cnrs.fr/) (CNRS and ENS Cachan)
- [Jalal Fadili](https://fadili.users.greyc.fr/) (ENSICAEN)
- [Bruno Galerne](https://www.idpoisson.fr/galerne/) (Orléans)
- [Anders Hansen](http://www.damtp.cam.ac.uk/research/afha/anders/) (Cambridge)
- [Gabriele Steidl](http://www.mathematik.uni-kl.de/imagepro/members/steidl/) (Kaiserslautern)
- [Clothilde Mélot](https://old.i2m.univ-amu.fr/~melot/index.html) (Marseille)
- [Gabriel Peyré](http://www.gpeyre.com) (CNRS and ENS)
- [Jared Tanner](https://people.maths.ox.ac.uk/tanner/) (Oxford)
- [Carola Schoenlieb](http://www.damtp.cam.ac.uk/user/cbs31/Home.html) (Cambridge)
- [Benedikt Wirth](http://www.uni-muenster.de/AMM/wirth/) (Münster)
